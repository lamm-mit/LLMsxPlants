{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ff8e1b-6969-4972-96c6-d2709be2c023",
   "metadata": {},
   "source": [
    "# BioLLM x Plants - Procedure Design - Q-As\n",
    "\n",
    "Rachel K. Luu, Ming Dao, Subra Suresh, Markus J. Buehler (2025) ENHANCING SCIENTIFIC INNOVATION IN LLMS: A FRAMEWORK APPLIED TO PLANT MECHANICS RESEARCH [full reference to be updated to be included here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3779f88b",
   "metadata": {},
   "source": [
    "## Load BioLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434640b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from typing import List, Optional, Sequence\n",
    "\n",
    "def completion_to_prompt(completion):\n",
    "    return \"<|start_header_id|>system<|end_header_id|>\\n<eot_id>\\n<|start_header_id|>user<|end_header_id|>\\n\" + \\\n",
    "           f\"{completion}<eot_id>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "\n",
    "def messages_to_prompt(messages):\n",
    "    prompt = \"<|start_header_id|>system<|end_header_id|>\\n<eot_id>\\n\"  \n",
    "    for message in messages:\n",
    "        if message.role == \"system\":\n",
    "            prompt += f\"system message<eot_id>\\n\"\n",
    "        elif message.role == \"user\":\n",
    "            prompt += f\"<|start_header_id|>user<|end_header_id|>\\n{message.content}<eot_id>\\n\"\n",
    "        elif message.role == \"assistant\":\n",
    "            prompt += f\"<|start_header_id|>assistant<|end_header_id|>\\n{message.content}<eot_id>\\n\"\n",
    "    prompt += \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    return prompt\n",
    "\n",
    "model_url = \"https://huggingface.co/rachelkluu/Llama3.1-8b-Instruct-CPT-SFT-DPO-09022024-Q8_0-GGUF/resolve/main/llama3.1-8b-instruct-cpt-sft-dpo-09022024-q8_0.gguf\"\n",
    "bioinspiredllm_q8 = LlamaCPP(\n",
    "    model_url=model_url,\n",
    "    model_path=None,\n",
    "    temperature=.1,\n",
    "    max_new_tokens=2048,\n",
    "    context_window=16000,\n",
    "    model_kwargs={\"n_gpu_layers\": -1},\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaca156",
   "metadata": {},
   "source": [
    "## Load RAG Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aab97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "Settings.llm = bioinspiredllm_q8\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"./PlantPapers/\"\n",
    ").load_data()\n",
    "\n",
    "Settings.chunk_size = 128\n",
    "Settings.chunk_overlap = 50\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = vector_index.as_query_engine(response_mode=\"compact\", similarity_top_k=10) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a903dc",
   "metadata": {},
   "source": [
    "# Generate Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bullet_points(response_text):\n",
    "    lines = response_text.split('\\n')\n",
    "    bullet_points = set()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(('- ', 'â€¢ ', '* ')):\n",
    "            bullet_points.add(line[2:].strip())\n",
    "        elif line and line[0].isdigit() and line[1:3] == '. ':\n",
    "            bullet_points.add(line[3:].strip())\n",
    "        elif line.startswith('[') and line[1].isdigit() and line[2] == ']':\n",
    "            bullet_points.add(line[3:].strip())\n",
    "    \n",
    "    return list(bullet_points)\n",
    "\n",
    "def get_technical_qs(num_generations, prompt):\n",
    "    \"\"\" Function to query for QUESTIONS wrt procedure prompt, extracts as bullet point list\"\"\"\n",
    "    all_questions = []\n",
    "    data_for_df = []\n",
    "\n",
    "    for gen_num in range(num_generations):\n",
    "        txt = f\"In order to '{prompt}', create a concise list of very basic and fundamental questions that explore the essential properties, definitions, and background relevant to this topic.\"\n",
    "        response = query_engine.query(txt)\n",
    "        questions = extract_bullet_points(response.response)\n",
    "        all_questions.append(questions)\n",
    "        for ques in questions:\n",
    "            data_for_df.append({\"Prompt\": prompt, \"Question\": ques})\n",
    "    flat_questions = list(itertools.chain.from_iterable(all_questions))\n",
    "    qcount = len(flat_questions)\n",
    "    df = pd.DataFrame(data_for_df, columns=[\"Prompt\", \"Question\"])\n",
    "\n",
    "    return df, flat_questions, qcount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d75a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Design a procedure that makes a composite out of pollen grains and rhapis excelsa leaves.\" #procedure task \n",
    "\n",
    "num_gen = 1 #number of sampling generations\n",
    "df, all_questions, qcount = get_technical_qs(num_gen, prompt) \n",
    "\n",
    "print(f\"{qcount} total questions were generated!\")\n",
    "print(f\"Here are the generated questions:\")\n",
    "for question in all_questions:\n",
    "    print(f\"- {question}\")\n",
    "\n",
    "#df is the dataframe holding all the data (prompt, question)\n",
    "#all_questions is list of all questions \n",
    "#qcount is # of generated questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e57eb9",
   "metadata": {},
   "source": [
    "# Generate Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_technicals(df):\n",
    "    \"\"\"Function that intakes the previously generated df to generate ANSWERS for the QUESTIONS\"\"\"\n",
    "    answers = []\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row[\"Question\"]\n",
    "        txt =f\"{question}. Answer concisely and accurately. If you don't know the answer or there isn't enough context from the provided information, state that this area needs further exploration. Do not use citations.\"\n",
    "        answer = query_engine.query(txt).response\n",
    "        answers.append(answer)\n",
    "        df.at[idx, \"Answer\"] = answer\n",
    "\n",
    "    return df, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, answers = ans_technicals(df)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Question: {row['Question']}\")\n",
    "    print(f\"Answer: {row['Answer']}\")\n",
    "    print() \n",
    "\n",
    "#df is overwritten now to contain (prompt, question, answer)\n",
    "#answers is a list of answers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc029e7",
   "metadata": {},
   "source": [
    "# Save Final Data to JSON File to be used in Multi-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"rhapispollenpaper\"\n",
    "\n",
    "json_data = df.to_json(orient='records', lines=True)\n",
    "with open(f\"{filename}.json\", 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065dec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plantmat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
